---
// Audio visualization page
---

<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" type="image/svg+xml" href="/favicon.svg" />
		<meta name="viewport" content="width=device-width" />
		<meta name="generator" content={Astro.generator} />
		<title>Audio Visualization - AI Video</title>
		<style>
			body {
				font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
				margin: 0;
				padding: 0;
				background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
				min-height: 100vh;
				display: flex;
				flex-direction: column;
				align-items: center;
				justify-content: center;
				color: white;
			}
			
			.container {
				text-align: center;
				max-width: 1200px;
				padding: 2rem;
			}
			
			h1 {
				font-size: 2.5rem;
				margin-bottom: 1rem;
				font-weight: 700;
			}
			
			.description {
				font-size: 1.1rem;
				margin-bottom: 2rem;
				opacity: 0.9;
			}
			
			.controls {
				margin-bottom: 2rem;
				display: flex;
				gap: 1rem;
				justify-content: center;
				flex-wrap: wrap;
			}
			
			button {
				background: rgba(255, 255, 255, 0.2);
				border: 2px solid rgba(255, 255, 255, 0.3);
				color: white;
				padding: 0.75rem 1.5rem;
				border-radius: 8px;
				font-size: 1rem;
				cursor: pointer;
				transition: all 0.3s ease;
				backdrop-filter: blur(10px);
			}
			
			button:hover {
				background: rgba(255, 255, 255, 0.3);
				border-color: rgba(255, 255, 255, 0.5);
				transform: translateY(-2px);
			}
			
			button:disabled {
				opacity: 0.5;
				cursor: not-allowed;
				transform: none;
			}
			
			.file-input {
				display: none;
			}
			
			.file-label {
				background: rgba(255, 255, 255, 0.2);
				border: 2px solid rgba(255, 255, 255, 0.3);
				color: white;
				padding: 0.75rem 1.5rem;
				border-radius: 8px;
				font-size: 1rem;
				cursor: pointer;
				transition: all 0.3s ease;
				backdrop-filter: blur(10px);
				display: inline-block;
			}
			
			.file-label:hover {
				background: rgba(255, 255, 255, 0.3);
				border-color: rgba(255, 255, 255, 0.5);
				transform: translateY(-2px);
			}
			
			.canvas-container {
				background: rgba(0, 0, 0, 0.3);
				border-radius: 12px;
				padding: 1rem;
				margin-bottom: 2rem;
				backdrop-filter: blur(10px);
			}
			
			#canvas {
				border-radius: 8px;
				box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
				background: rgba(0, 0, 0, 0.8);
			}
			
			.audio-info {
				background: rgba(255, 255, 255, 0.1);
				padding: 1rem;
				border-radius: 8px;
				margin-bottom: 1rem;
				backdrop-filter: blur(10px);
			}
			
			.rms-display {
				font-size: 1.2rem;
				font-weight: 600;
				margin-bottom: 0.5rem;
			}
			
			.audio-status {
				font-size: 0.9rem;
				opacity: 0.8;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>Audio Visualization</h1>
			<p class="description">Upload an audio file and watch the canvas animate to the music's rhythm</p>
			
			<div class="controls">
				<input type="file" id="audioFile" class="file-input" accept="audio/*" />
				<label for="audioFile" class="file-label">Choose Audio File</label>
				<button id="playBtn" disabled>Play</button>
				<button id="pauseBtn" disabled>Pause</button>
				<button id="stopBtn" disabled>Stop</button>
			</div>
			
			<div class="audio-info">
				<div class="rms-display">RMS: <span id="rmsValue">0.00</span></div>
				<div class="audio-status" id="audioStatus">No audio loaded</div>
			</div>
			
			<div class="canvas-container">
				<canvas id="canvas" width="800" height="400"></canvas>
			</div>
		</div>

		<script>
			// Audio context and analysis setup
			let audioContext;
			let audioSource;
			let analyser;
			let audioElement;
			let isPlaying = false;
			let audioSourceCreated = false;
			
			// Canvas setup
			let canvas;
			let ctx;
			let animationId;
			
			// Visualization objects
			let circles = [];
			let bars = [];
			let particles = [];
			
			// DOM elements
			const playBtn = document.getElementById('playBtn');
			const pauseBtn = document.getElementById('pauseBtn');
			const stopBtn = document.getElementById('stopBtn');
			const fileInput = document.getElementById('audioFile');
			const rmsValue = document.getElementById('rmsValue');
			const audioStatus = document.getElementById('audioStatus');
			
			// Initialize canvas
			function initCanvas() {
				canvas = document.getElementById('canvas');
				ctx = canvas.getContext('2d');
				
				// Create initial visualization objects
				createVisualizationObjects();
				
				console.log('Canvas initialized successfully');
			}
			
			// Create visualization objects
			function createVisualizationObjects() {
				// Create circles
				circles = [];
				for (let i = 0; i < 5; i++) {
					circles.push({
						x: 400,
						y: 200,
						radius: 20 + i * 10,
						scale: 1,
						rotation: 0,
						color: `hsl(${200 + i * 30}, 70%, 60%)`
					});
				}
				
				// Create bars
				bars = [];
				for (let i = 0; i < 20; i++) {
					bars.push({
						x: 50 + i * 35,
						y: 350,
						width: 30,
						height: 50,
						color: `hsl(${180 + i * 9}, 80%, 60%)`
					});
				}
				
				// Create particles
				particles = [];
				for (let i = 0; i < 50; i++) {
					particles.push({
						x: Math.random() * 800,
						y: Math.random() * 400,
						radius: 2 + Math.random() * 3,
						color: `hsl(${Math.random() * 360}, 80%, 70%)`,
						opacity: 0.6
					});
				}
			}
			
			// Initialize audio context
			function initAudio() {
				try {
					audioContext = new (window.AudioContext || window.webkitAudioContext)();
					analyser = audioContext.createAnalyser();
					analyser.fftSize = 256;
					analyser.smoothingTimeConstant = 0.8;
					console.log('Audio context initialized successfully');
				} catch (error) {
					console.error('Error initializing audio context:', error);
					audioStatus.textContent = 'Error: Audio context not supported';
				}
			}
			
			// Handle file selection
			fileInput.addEventListener('change', (e) => {
				const file = e.target.files[0];
				if (file) {
					loadAudioFile(file);
				}
			});
			
			// Load audio file
			function loadAudioFile(file) {
				const url = URL.createObjectURL(file);
				audioElement = new Audio(url);
				audioElement.crossOrigin = 'anonymous';
				audioSourceCreated = false;
				
				audioElement.addEventListener('canplay', () => {
					audioStatus.textContent = `Loaded: ${file.name}`;
					playBtn.disabled = false;
					pauseBtn.disabled = true;
					stopBtn.disabled = true;
					console.log('Audio file loaded successfully');
				});
				
				audioElement.addEventListener('ended', () => {
					stopAudio();
				});
				
				audioElement.addEventListener('error', (e) => {
					console.error('Audio loading error:', e);
					audioStatus.textContent = 'Error loading audio file';
				});
			}
			
			// Play audio
			playBtn.addEventListener('click', () => {
				if (audioElement && !isPlaying) {
					playAudio();
				}
			});
			
			// Pause audio
			pauseBtn.addEventListener('click', () => {
				if (isPlaying) {
					pauseAudio();
				}
			});
			
			// Stop audio
			stopBtn.addEventListener('click', () => {
				if (isPlaying) {
					stopAudio();
				}
			});
			
			// Play audio function
			async function playAudio() {
				try {
					if (!audioContext) {
						initAudio();
					}
					
					if (audioContext.state === 'suspended') {
						await audioContext.resume();
					}
					
					// Only create MediaElementSource once per audio element
					if (!audioSourceCreated) {
						audioSource = audioContext.createMediaElementSource(audioElement);
						audioSource.connect(analyser);
						analyser.connect(audioContext.destination);
						audioSourceCreated = true;
						console.log('Audio source connected to analyzer');
					}
					
					await audioElement.play();
					isPlaying = true;
					
					playBtn.disabled = true;
					pauseBtn.disabled = false;
					stopBtn.disabled = false;
					
					audioStatus.textContent = 'Playing...';
					
					// Start animation
					animate();
				} catch (error) {
					console.error('Error playing audio:', error);
					audioStatus.textContent = 'Error playing audio';
				}
			}
			
			// Pause audio function
			function pauseAudio() {
				audioElement.pause();
				isPlaying = false;
				
				playBtn.disabled = false;
				pauseBtn.disabled = true;
				stopBtn.disabled = false;
				
				audioStatus.textContent = 'Paused';
				
				// Stop animation
				if (animationId) {
					cancelAnimationFrame(animationId);
				}
			}
			
			// Stop audio function
			function stopAudio() {
				audioElement.pause();
				audioElement.currentTime = 0;
				isPlaying = false;
				
				playBtn.disabled = false;
				pauseBtn.disabled = true;
				stopBtn.disabled = true;
				
				audioStatus.textContent = 'Stopped';
				
				// Stop animation
				if (animationId) {
					cancelAnimationFrame(animationId);
				}
				
				// Reset visualization
				resetVisualization();
			}
			
			// Reset visualization to initial state
			function resetVisualization() {
				createVisualizationObjects();
				draw();
				rmsValue.textContent = '0.00';
			}
			
			// Draw function
			function draw() {
				// Clear canvas
				ctx.fillStyle = 'rgba(0, 0, 0, 0.8)';
				ctx.fillRect(0, 0, 800, 400);
				
				// Draw circles
				circles.forEach(circle => {
					ctx.save();
					ctx.translate(circle.x, circle.y);
					ctx.rotate(circle.rotation);
					ctx.scale(circle.scale, circle.scale);
					
					ctx.beginPath();
					ctx.arc(0, 0, circle.radius, 0, Math.PI * 2);
					ctx.fillStyle = circle.color;
					ctx.fill();
					
					ctx.restore();
				});
				
				// Draw bars
				bars.forEach(bar => {
					ctx.fillStyle = bar.color;
					ctx.fillRect(bar.x - bar.width/2, bar.y - bar.height, bar.width, bar.height);
				});
				
				// Draw particles
				particles.forEach(particle => {
					ctx.globalAlpha = particle.opacity;
					ctx.fillStyle = particle.color;
					ctx.beginPath();
					ctx.arc(particle.x, particle.y, particle.radius, 0, Math.PI * 2);
					ctx.fill();
				});
				
				ctx.globalAlpha = 1;
			}
			
			// Main animation loop
			function animate() {
				if (!isPlaying || !analyser) return;
				
				const bufferLength = analyser.frequencyBinCount;
				const dataArray = new Uint8Array(bufferLength);
				analyser.getByteFrequencyData(dataArray);
				
				// Calculate RMS value
				let sum = 0;
				for (let i = 0; i < bufferLength; i++) {
					sum += dataArray[i] * dataArray[i];
				}
				const rms = Math.sqrt(sum / bufferLength) / 255;
				
				// Update RMS display
				rmsValue.textContent = rms.toFixed(3);
				
				// Debug: log RMS value occasionally
				if (Math.random() < 0.01) {
					console.log('RMS:', rms, 'Max frequency:', Math.max(...dataArray));
				}
				
				// Animate circles based on RMS
				circles.forEach((circle, i) => {
					circle.scale = 1 + rms * (i + 1) * 0.5;
					circle.rotation += rms * 0.1 * (i + 1);
				});
				
				// Animate bars based on frequency data
				bars.forEach((bar, i) => {
					const frequencyIndex = Math.floor(i * bufferLength / bars.length);
					const frequencyValue = dataArray[frequencyIndex] / 255;
					bar.height = 50 + frequencyValue * 200;
					bar.color = `hsl(${180 + frequencyValue * 180}, 80%, 60%)`;
				});
				
				// Animate particles
				particles.forEach((particle, i) => {
					const speed = rms * 5;
					const angle = (i * 137.5 + Date.now() * 0.001) % (Math.PI * 2);
					
					particle.x += Math.cos(angle) * speed;
					particle.y += Math.sin(angle) * speed;
					
					// Wrap particles around screen
					if (particle.x < 0) particle.x = 800;
					if (particle.x > 800) particle.x = 0;
					if (particle.y < 0) particle.y = 400;
					if (particle.y > 400) particle.y = 0;
					
					// Pulse opacity based on RMS
					particle.opacity = 0.3 + rms * 0.7;
				});
				
				// Draw everything
				draw();
				
				animationId = requestAnimationFrame(animate);
			}
			
			// Initialize everything when page loads
			document.addEventListener('DOMContentLoaded', () => {
				initCanvas();
				initAudio();
			});
		</script>
	</body>
</html> 